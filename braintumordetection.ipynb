{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR=\"BrainTumorData/Brain Tumor Data Set\"\n",
    "number_of_images={}\n",
    "\n",
    "for dir in os.listdir(ROOT_DIR):\n",
    "    number_of_images[dir]=len(os.listdir(os.path.join(ROOT_DIR,dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Brain Tumor', 8), ('Healthey', 7)])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_images.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"BrainTumorData/Brain Tumor Data Set\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFolder(p,split):\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(\"./\"+p):\n",
    "        os.mkdir(\"./\"+p)\n",
    "        for dir in os.listdir(ROOT_DIR):\n",
    "            os.makedirs(\"./\"+p+\"/\"+dir)\n",
    "            for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR,dir)),\n",
    "                             size=(math.floor(split*number_of_images[dir])-2),replace=False):\n",
    "                O=os.path.join(ROOT_DIR,dir,img)\n",
    "                D=os.path.join(\"./\"+p,dir)\n",
    "                shutil.copy(O,D)\n",
    "                os.remove(O)\n",
    "    else:\n",
    "        print(\"Folder Exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Exist\n"
     ]
    }
   ],
   "source": [
    "dataFolder(\"train\",0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Exist\n"
     ]
    }
   ],
   "source": [
    "dataFolder(\"val\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Exist\n"
     ]
    }
   ],
   "source": [
    "dataFolder(\"test\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Brain Tumor', 8), ('Healthey', 7)])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_images={}\n",
    "\n",
    "for dir in os.listdir(ROOT_DIR):\n",
    "    number_of_images[dir]=len(os.listdir(os.path.join(ROOT_DIR,dir)))\n",
    "    \n",
    "\n",
    "number_of_images.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,MaxPool2D,Dropout,GlobalAveragePooling2D,Flatten,Dense,BatchNormalization\n",
    "from keras.models import Sequential\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 222, 222, 16)      448       \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 220, 220, 36)      5220      \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 110, 110, 36)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 108, 108, 64)      20800     \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 54, 54, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 26, 26, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                5537856   \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,638,245\n",
      "Trainable params: 5,638,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=16,kernel_size=(3,3),activation='relu',input_shape=(224,224,3)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=36,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64,activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=keras.losses.binary_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingImages1(path):\n",
    "    image_data=ImageDataGenerator(zoom_range=0.2,shear_range=0.2,rescale=1/255,horizontal_flip=True)\n",
    "    image=image_data.flow_from_directory(directory=path,target_size=(224,224),batch_size=16,class_mode='binary')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 167 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path=\"./train\"\n",
    "train_data=preprocessingImages1(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingImages2(path):\n",
    "    image_data=ImageDataGenerator(rescale=1/255)\n",
    "    image=image_data.flow_from_directory(directory=path,target_size=(224,224),batch_size=16,class_mode='binary')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path=\"./test\"\n",
    "test_data=preprocessingImages2(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path=\"./val\"\n",
    "val_data=preprocessingImages2(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_accuracy\",min_delta=0.01,patience=3,verbose=1,mode=\"auto\")\n",
    "mc=ModelCheckpoint(monitor=\"val_accuracy\",filepath=\"./bestmodel.h5\",verbose=1,save_best_only=True,mode='auto')\n",
    "cd=[es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.7479WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 32 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 32 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy did not improve from 0.75000\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.5321 - accuracy: 0.7479 - val_loss: 0.7079 - val_accuracy: 0.7188\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.7344WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.5846 - accuracy: 0.7344\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.7395WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.5569 - accuracy: 0.7395\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.7143WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.5663 - accuracy: 0.7143\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5072 - accuracy: 0.7479WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.5072 - accuracy: 0.7479\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.7563WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.5562 - accuracy: 0.7563\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5972 - accuracy: 0.6471WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.5972 - accuracy: 0.6471\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.8125WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 1s/step - loss: 0.5093 - accuracy: 0.8125\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.7815WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 1s/step - loss: 0.4866 - accuracy: 0.7815\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4441 - accuracy: 0.8235WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 976ms/step - loss: 0.4441 - accuracy: 0.8235\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.7815WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 1s/step - loss: 0.5378 - accuracy: 0.7815\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4328 - accuracy: 0.7983WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.4328 - accuracy: 0.7983\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8067WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 10s 1s/step - loss: 0.4481 - accuracy: 0.8067\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.8655WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.4568 - accuracy: 0.8655\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4660 - accuracy: 0.7563WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 989ms/step - loss: 0.4660 - accuracy: 0.7563\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.7395WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 1s/step - loss: 0.4968 - accuracy: 0.7395\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8067WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 976ms/step - loss: 0.4115 - accuracy: 0.8067\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.7891WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 1s/step - loss: 0.4107 - accuracy: 0.7891\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3956 - accuracy: 0.8125WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.3956 - accuracy: 0.8125\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3711 - accuracy: 0.8235WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 965ms/step - loss: 0.3711 - accuracy: 0.8235\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.8403WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 963ms/step - loss: 0.3365 - accuracy: 0.8403\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8571WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 958ms/step - loss: 0.3762 - accuracy: 0.8571\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8235WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 1s/step - loss: 0.4270 - accuracy: 0.8235\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.8992WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 964ms/step - loss: 0.3360 - accuracy: 0.8992\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.8235WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 961ms/step - loss: 0.3584 - accuracy: 0.8235\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8571WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 10s 1s/step - loss: 0.3297 - accuracy: 0.8571\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.9244WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 940ms/step - loss: 0.2669 - accuracy: 0.9244\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.8739WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.2660 - accuracy: 0.8739\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.9297WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 1s/step - loss: 0.2100 - accuracy: 0.9297\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.8655WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 939ms/step - loss: 0.2462 - accuracy: 0.8655\n"
     ]
    }
   ],
   "source": [
    "hs=model.fit_generator(generator=train_data,\n",
    "                       steps_per_epoch=8,\n",
    "                       epochs=30,\n",
    "                       verbose=1,\n",
    "                       validation_data=val_data,\n",
    "                       validation_steps=32,\n",
    "                       callbacks=cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=hs.history\n",
    "h.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h['accuracy'])\n",
    "plt.plot(h['val_accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"acc vs val\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ./bestmodel.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kumar\\OneDrive\\Desktop\\Brain Tumor Detection\\braintumordetection.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kumar/OneDrive/Desktop/Brain%20Tumor%20Detection/braintumordetection.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kumar/OneDrive/Desktop/Brain%20Tumor%20Detection/braintumordetection.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m=\u001b[39mload_model(\u001b[39m\"\u001b[39;49m\u001b[39m./bestmodel.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\kumar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    205\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 206\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    208\u001b[0m   \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(filepath_str, \u001b[39mcompile\u001b[39m, options)\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at ./bestmodel.h5"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(\"bestmodel.hs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ef873d6a9fb09128c51ca24f57d685a29a4c4cb4919f17482f419e89ebc151a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
